<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description"
    content="TC-IDM: Pixels to World: Grounding Video Generation for Executable Zero-shot Robot Motion.">
  <meta name="keywords" content="Robotics, Video Generation, Zero-shot, Dexterous Hand, TC-IDM, World Model">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>TC-IDM: Pixels to World</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <style>
    html {
      scroll-behavior: smooth;
    }

    body {
      font-family: 'Noto Sans', sans-serif;
    }

    .publication-title {
      font-family: 'Castoro', serif;
      /* 标题使用衬线字体 */
      font-weight: bold;
    }

    /* 左侧导航栏 Sticky 效果 */
    .menu-sticky {
      position: -webkit-sticky;
      position: sticky;
      top: 40px;
      /* 距离顶部的距离 */
      max-height: calc(100vh - 40px);
      overflow-y: auto;
    }

    .menu-label {
      font-size: 0.9em;
      letter-spacing: 0.1em;
      color: #363636;
      font-weight: bold;
      margin-bottom: 1em;
    }

    .menu-list a {
      border-radius: 2px;
      color: #666;
      padding: 0.5em 0.75em;
    }

    .menu-list a:hover {
      background-color: #f5f5f5;
      color: #363636;
    }

    .menu-list a.is-active {
      background-color: #363636;
      color: #fff;
    }

    /* 章节样式 */
    .content-section {
      margin-bottom: 3rem;
      padding-top: 1rem;
      /* 为锚点定位留出空间 */
    }

    .section-title {
      border-bottom: 1px solid #dbdbdb;
      padding-bottom: 0.5rem;
      margin-bottom: 1.5rem;
      font-family: 'Google Sans', sans-serif;
      font-weight: 500;
    }

    /* 视频 Grid 布局 */
    .video-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
      gap: 20px;
    }

    .video-card {
      background: #fff;
      border-radius: 8px;
      overflow: hidden;
      box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
    }

    .video-caption {
      padding: 10px;
      text-align: center;
      font-size: 0.9rem;
      color: #555;
    }

    /* Abstract 黑色背景块  */
    /* .abstract-box {
        background-color: #f5f5f5; 
        border-left: 5px solid #363636;
        padding: 1.5rem;
        border-radius: 4px;
    } */

    .content-section {
      margin-bottom: 3rem;
      /* 这里设置锚点定位时的顶部偏移量，类似于之前的 -50px */
      scroll-margin-top: 60px;
    }
  </style>
</head>

<body>

  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
    <div class="navbar-menu">
      <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
        <a class="navbar-item" href="https://github.com/wsbaiyi">
          <span class="icon">
            <i class="fas fa-home"></i>
          </span>
        </a>
      </div>
    </div>
  </nav>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">

            <h1 class="title is-1 publication-title">
              TC-IDM
            </h1>
            <h2 class="subtitle is-3 publication-title" style="color: #555;">
              Pixels to World: Grounding Video Generation for <br>Executable Zero-shot Robot Motion
            </h2>

            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="#">Your Name</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="#">Co-Author Name</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="#">Co-Author Name</a><sup>2</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>University Name,</span>
              <span class="author-block"><sup>2</sup>Institution Name</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <span class="link-block">
                  <a href="#" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon"><i class="fas fa-file-pdf"></i></span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2400.xxxxx" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon"><i class="ai ai-arxiv"></i></span>
                    <span>arXiv</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="#" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon"><i class="fab fa-youtube"></i></span>
                    <span>Video</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://github.com/wsbaiyi/TC-IDM" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon"><i class="fab fa-github"></i></span>
                    <span>Code</span>
                  </a>
                </span>
              </div>
            </div>

          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <div style="width: 100%; text-align: center;">
          <video id="demo-video" autoplay muted loop playsinline controls
            style="width: 100%; border-radius: 10px; box-shadow: 0 0 20px rgba(0,0,0,0.1);">
            <source src="./static/videos/demo.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
          <img src="./static/images/teaser_final_final.png" alt="Teaser"
            style="width: 100%; border-radius: 10px; background: #eee; min-height: 300px; object-fit: cover;">
        </div>

        <h2 class="subtitle has-text-centered" style="margin-top: 15px;">
          <strong>Tool-centric world-model-based IDM</strong> achieves stronger generalization than VLA baselines,
          providing a clean and rigid structure that is easier to learn and transfer across embodiments.
        </h2>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-widescreen">
      <div class="columns">

        <div class="column is-2 is-hidden-mobile">
          <aside class="menu menu-sticky">
            <p class="menu-label">Content</p>
            <ul class="menu-list">
              <li><a href="#abstract">Abstract</a></li>
              <li><a href="#error">Error Range Analysis</a></li>
              <li><a href="#camera">Generalization Across Camera Variations</a></li>
              <li><a href="#deformable">Generalization for Deformable Objects</a></li>
              <li><a href="#long-horizon">Long Horizon Tasks</a></li>
              <li><a href="#cross-embodiment">Cross-Embodiment</a></li>
              <li><a href="#migration">Human-to-Dexterous Hand Migration</a></li>
            </ul>
          </aside>
        </div>

        <div class="column is-10">

          <div id="abstract" class="content-section">
            <h2 class="title is-3 section-title">Abstract</h2>
            <div class="content has-text-justified ">
              <p>
                The vision–language–action (VLA) paradigm has enabled powerful robotic control by leveraging
                vision–language models, but its reliance on large-scale, high-quality robot data limits its
                generalization. Generative world models offer a promising alternative for general-purpose embodied AI,
                yet a critical gap remains between their pixel-level plans and physically executable actions. To this
                end, we propose the Tool-Centric Inverse Dynamics Model (TC-IDM). By focusing on the tool’s imagined
                trajectory as synthesized by the world model, TC-IDM establishes a robust intermediate representation
                that bridges the gap between visual planning and physical control. TC-IDM extracts the tool’s point
                cloud trajectories via segmentation and 3D motion estimation from generated videos. Considering diverse
                tool attributes, our architecture employs decoupled action heads to project these planned trajectories
                into 6-DoF end-effector motions and corresponding control signals. This ’plan-and-translate’ paradigm
                not only supports a wide range of end-effectors but also significantly improves viewpoint invariance.
                Furthermore, it exhibits strong generalization capabilities across long-horizon and out-of-distribution
                tasks, including interacting with deformable objects. In real-world evaluations, the world model with
                TC-IDM achieves an average success rate of 61.11%, with 77.7% on simple tasks, and 38.46% on zero-shot
                deformable object tasks—substantially outperforming end-to-end VLA-style baselines and other IDMs.
              </p>
            </div>
          </div>


          <div id="error" class="content-section">
            <h2 class="title is-3 section-title">Error Range Analysis</h2>
            <div class="content has-text-justified">
              <p>
                Achieves sub-4cm precision in dart placement tasks, demonstrating superior plan-to-execution fidelity
                over VLA baselines.
              </p>

              <div class="columns is-centered is-variable is-2">

                <div class="column is-4">
                  <div class="video-card">
                    <video autoplay muted loop playsinline width="100%">
                      <source src="./static/videos/pred_dart.mp4" type="video/mp4">
                    </video>
                    <div class="video-caption">Generated Manipulation</div>
                  </div>
                </div>

                <div class="column is-4">
                  <div class="video-card">
                    <video autoplay muted loop playsinline width="100%">
                      <source src="./static/videos/ours_dart.mp4" type="video/mp4">
                    </video>
                    <div class="video-caption"><strong>TC-IDM (Ours)</strong></div>
                  </div>
                </div>

                <div class="column is-4">
                  <div class="video-card">
                    <video autoplay muted loop playsinline width="100%">
                      <source src="./static/videos/anypose_dart.mp4" type="video/mp4">
                    </video>
                    <div class="video-caption">Anypos</div>
                  </div>
                </div>

              </div>
            </div>
          </div>

          <div id="camera" class="content-section">
            <h2 class="title is-3 section-title">Generalization Across Camera Variations</h2>
            <div class="content">
              <p>
                Zero-shot transfer to unseen cameras (Apple Pro, D435i) and varying lighting conditions without any
                fine-tuning.
              </p>

              <div class="columns is-centered is-variable is-2">

                <div class="column is-4">
                  <div class="video-card">
                    <video autoplay muted loop playsinline width="100%">
                      <source src="./static/videos/apple_pro.mp4" type="video/mp4">
                    </video>
                    <div class="video-caption">Apple Pro Camera</div>
                  </div>
                </div>

                <div class="column is-4">
                  <div class="video-card">
                    <video autoplay muted loop playsinline width="100%">
                      <source src="./static/videos/D435i.mp4" type="video/mp4">
                    </video>
                    <div class="video-caption">Realsense D435i Camera</div>
                  </div>
                </div>

                <div class="column is-4">
                  <div class="video-card">
                    <video autoplay muted loop playsinline width="100%">
                      <source src="./static/videos/gt_bread.mp4" type="video/mp4">
                    </video>
                    <div class="video-caption">Real Robot Execution</div>
                  </div>
                </div>

              </div>
            </div>
          </div>




          <div id="deformable" class="content-section">
            <h2 class="title is-3 section-title">Generalization for Deformable Objects</h2>
            <div class="content">
              <p>
                Successfully handles non-rigid objects (e.g., cloth removal) with a 38.46% success rate, despite being
                trained exclusively on rigid data.
              </p>

              <div class="columns is-centered">

                <div class="column is-5">
                  <div class="video-card">
                    <video autoplay muted loop playsinline width="100%">
                      <source src="./static/videos/pred_deformable.mp4" type="video/mp4">
                    </video>
                    <div class="video-caption">Generated Manipulation</div>
                  </div>
                </div>

                <div class="column is-5">
                  <div class="video-card">
                    <video autoplay muted loop playsinline width="100%">
                      <source src="./static/videos/gt_deformable.mp4" type="video/mp4">
                    </video>
                    <div class="video-caption">Real Robot Execution</div>
                  </div>
                </div>

              </div>
            </div>
          </div>


          <div id="long-horizon" class="content-section">
            <h2 class="title is-3 section-title">Long Horizon Tasks</h2>
            <div class="content">
              <p>
                Executes complex multi-stage tasks, such as 6-step hoodie folding, in a zero-shot manner without
                intermediate replanning.
              </p>

              <div class="columns is-centered">

                <div class="column is-5">
                  <div class="video-card">
                    <video autoplay muted loop playsinline width="100%">
                      <source src="./static/videos/long_horizon.mp4" type="video/mp4">
                    </video>
                    <!-- <div class="video-caption">Xylophone Playing</div> -->
                  </div>
                </div>
              </div>
            </div>
          </div>


          <div id="cross-embodiment" class="content-section">
            <h2 class="title is-3 section-title">Cross-Embodiment</h2>
            <div class="content">
              <p>
                Seamlessly transfers motion priors from single-arm Franka to dual-arm UR5 systems for dynamic tasks like
                xylophone playing.
              </p>

              <div class="columns is-centered">

                <div class="column is-5">
                  <div class="video-card">
                    <video autoplay muted loop playsinline width="100%">
                      <source src="./static/videos/pred.mp4" type="video/mp4">
                    </video>
                    <div class="video-caption">Generated Manipulation</div>
                  </div>
                </div>

                <div class="column is-5">
                  <div class="video-card">
                    <video autoplay muted loop playsinline width="100%">
                      <source src="./static/videos/gt.mp4" type="video/mp4">
                    </video>
                    <div class="video-caption">Real Robot Execution</div>
                  </div>
                </div>

              </div>
            </div>
          </div>



          <div id="migration" class="content-section">
            <h2 class="title is-3 section-title">Human-to-Dexterous Hand Migration</h2>
            <div class="content">
              <p>
                Enables zero-shot retargeting to various multi-fingered hands (BrainCo, Inspire) via embodiment-agnostic
                motion representations.
              </p>

              <div class="columns is-centered">
                <div class="column is-5">
                  <div class="video-card">
                    <video autoplay muted loop playsinline width="100%">
                      <source src="./static/videos/cloth.mp4" type="video/mp4">
                    </video>
                    <div class="video-caption">Generated Human Video (Cloth Removal)</div>
                  </div>
                </div>
                <div class="column is-5">
                  <div class="video-card">
                    <video autoplay muted loop playsinline width="100%">
                      <source src="./static/videos/hand_cloth.mp4" type="video/mp4">
                    </video>
                    <div class="video-caption">Dexterous Hand Execution (Cloth Removal)</div>
                  </div>
                </div>
              </div>

              <div class="columns is-centered">
                <div class="column is-5">
                  <div class="video-card">
                    <video autoplay muted loop playsinline width="100%">
                      <source src="./static/videos/ball.mp4" type="video/mp4">
                    </video>
                    <div class="video-caption">Generated Human Video (Balloon Hitting)</div>
                  </div>
                </div>
                <div class="column is-5">
                  <div class="video-card">
                    <video autoplay muted loop playsinline width="100%">
                      <source src="./static/videos/hand_ballon.mp4" type="video/mp4">
                    </video>
                    <div class="video-caption">Dexterous Hand Execution (Balloon Hitting)</div>
                  </div>
                </div>
              </div>

            </div>
          </div>

        </div>
      </div>
    </div>
  </section>

  <section class="section" id="BibTeX" style="background-color: #f5f5f5;">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{pixels2world2026,
  title={Pixels to World: Grounding Video Generation for Executable Zero-shot Robot Motion},
  author={Your Name and Co-Author},
  journal={arXiv preprint arXiv:2400.xxxxx},
  year={2026}
}</code></pre>
    </div>
  </section>

  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <a class="icon-link" href="#">
          <i class="fas fa-file-pdf"></i>
        </a>
        <a class="icon-link" href="https://github.com/wsbaiyi/Pixels-to-World" class="external-link" disabled>
          <i class="fab fa-github"></i>
        </a>
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
              Template borrowed from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>



</body>

</html>